this is a react native project with an expo framework. Rules:
1. we are making a mohbile app. we will use components and hooks respectively
2. use expo
3. use expo router for navigation (file based routing)
4. create functional code in line with modern expo
5. all business logic will be processed in the front end

The flow of this project is for a vision assistant. the user will record an audio-based question and receive an example. For example, the user could ask "what color is this pencil" and the assistant will respond with "it is blue".

The flow is as follows: 
1. the user will record an audio-based question (done)
2. a photo is taken (done)
3. the audio is transcribed into text using openai whisper. the base code in javascript is: 

"import fs from "fs";
import OpenAI from "openai";

const openai = new OpenAI();

const transcription = await openai.audio.transcriptions.create({
  file: fs.createReadStream("/path/to/file/audio.mp3"),
  model: "whisper-1",
});

console.log(transcription.text);" 

4. the text and photo are sent to openai 
5. all files are deleted from the device
6. the response is processed with elevenlabs and played out loud
7. the user can record another question or leave